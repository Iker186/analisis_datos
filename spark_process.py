from pyspark.sql import SparkSession
from pyspark.sql.functions import col, year, to_date
import os

# âœ… Iniciar sesiÃ³n de Spark
spark = SparkSession.builder.appName("SocialMediaProcessing").getOrCreate()

# ğŸ“¥ Cargar dataset desde CSV
df = spark.read.csv("./data/social_media.csv", header=True, inferSchema=True)

# ğŸ§¹ Limpieza de datos
df = df.dropna()

# ğŸ‚ Calcular edad a partir del DOB
df = df.withColumn("DOB", to_date(col("DOB"), "yyyy-MM-dd"))
df = df.withColumn("Edad", year("2025-01-01") - year(col("DOB")))

# ğŸ¯ Seleccionar columnas relevantes
columns_to_keep = ["UserID", "Country", "City", "Gender", "Interests", "Edad"]
df_final = df.select(columns_to_keep)

# ğŸ“Š Agregar anÃ¡lisis de interÃ©s principal
df_interests = df_final.groupBy("Interests").count().orderBy("count", ascending=False)

# ğŸ“‚ Crear carpeta para resultados si no existe
if not os.path.exists("results"):
    os.makedirs("results")

# ğŸ’¾ Guardar resultados procesados
df_final.write.mode("overwrite").json("results/processed_data.json")
df_interests.write.mode("overwrite").json("results/interests_summary.json")

print("âœ… Proceso completado y datos guardados en 'results/'")
